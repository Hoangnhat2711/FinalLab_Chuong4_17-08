{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from nltk.util import ngrams\n",
    "# Lấy dữ liệu\n",
    "file_list = os.listdir(r\"Data_preprocessing\")\n",
    "\n",
    "# Đọc nội dung của từng tệp văn bản\n",
    "for file_name in file_list:\n",
    "  with open(os.path.join(\"Data_preprocessing\", file_name),'r',encoding='utf-8') as f:\n",
    "    Data = f.read()\n",
    "    Data=word_tokenize(Data)\n",
    "    # Khởi tạo đối tượng CountVectorizer\n",
    "    # Tham số ngram_range=(1,2) cho biết chúng ta muốn sử dụng N-grams từ 1 đến 2.\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "    # Biểu diễn vector đặc trưng cho các câu\n",
    "    features = vectorizer.fit_transform(Data)\n",
    "\n",
    "   \n",
    "    # Mỗi hàng trong ma trận tương ứng với một câu và mỗi cột tương ứng với một N-gram trong tất cả các câu. Giá trị của mỗi phần tử trong ma trận là số lần xuất hiện của N-gram đó trong câu tương ứng.\n",
    "    arr=features.toarray()\n",
    "\n",
    "    print(\"Vocabulary N-gram:\",file_name)\n",
    "\n",
    "    print(\"1-gram\",arr[0])\n",
    "    print(\"2-gram\",arr[1])\n",
    "    print(\"-------------------\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
